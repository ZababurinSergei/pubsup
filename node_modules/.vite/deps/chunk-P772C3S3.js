import {
  pushable
} from "./chunk-MFOH7TLG.js";
import {
  peerIdFromString,
  randomBytes
} from "./chunk-CVLG3IBJ.js";
import {
  Uint8ArrayList
} from "./chunk-AFTIF377.js";
import {
  raceSignal
} from "./chunk-KI5O2YSF.js";
import {
  fromString
} from "./chunk-4FLSKMQ2.js";
import {
  pDefer
} from "./chunk-YUNCDTIA.js";
import {
  AbortError,
  CodeError,
  TypedEventEmitter,
  setMaxListeners
} from "./chunk-EZU2LKBL.js";
import {
  __commonJS,
  __toESM,
  alloc,
  equals
} from "./chunk-2CLIZDD7.js";

// ../../node_modules/murmurhash3js-revisited/lib/murmurHash3js.js
var require_murmurHash3js = __commonJS({
  "../../node_modules/murmurhash3js-revisited/lib/murmurHash3js.js"(exports, module) {
    (function(root, undefined2) {
      "use strict";
      var library = {
        "version": "3.0.0",
        "x86": {},
        "x64": {},
        "inputValidation": true
      };
      function _validBytes(bytes) {
        if (!Array.isArray(bytes) && !ArrayBuffer.isView(bytes)) {
          return false;
        }
        for (var i = 0; i < bytes.length; i++) {
          if (!Number.isInteger(bytes[i]) || bytes[i] < 0 || bytes[i] > 255) {
            return false;
          }
        }
        return true;
      }
      function _x86Multiply(m, n) {
        return (m & 65535) * n + (((m >>> 16) * n & 65535) << 16);
      }
      function _x86Rotl(m, n) {
        return m << n | m >>> 32 - n;
      }
      function _x86Fmix(h) {
        h ^= h >>> 16;
        h = _x86Multiply(h, 2246822507);
        h ^= h >>> 13;
        h = _x86Multiply(h, 3266489909);
        h ^= h >>> 16;
        return h;
      }
      function _x64Add(m, n) {
        m = [m[0] >>> 16, m[0] & 65535, m[1] >>> 16, m[1] & 65535];
        n = [n[0] >>> 16, n[0] & 65535, n[1] >>> 16, n[1] & 65535];
        var o = [0, 0, 0, 0];
        o[3] += m[3] + n[3];
        o[2] += o[3] >>> 16;
        o[3] &= 65535;
        o[2] += m[2] + n[2];
        o[1] += o[2] >>> 16;
        o[2] &= 65535;
        o[1] += m[1] + n[1];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[0] += m[0] + n[0];
        o[0] &= 65535;
        return [o[0] << 16 | o[1], o[2] << 16 | o[3]];
      }
      function _x64Multiply(m, n) {
        m = [m[0] >>> 16, m[0] & 65535, m[1] >>> 16, m[1] & 65535];
        n = [n[0] >>> 16, n[0] & 65535, n[1] >>> 16, n[1] & 65535];
        var o = [0, 0, 0, 0];
        o[3] += m[3] * n[3];
        o[2] += o[3] >>> 16;
        o[3] &= 65535;
        o[2] += m[2] * n[3];
        o[1] += o[2] >>> 16;
        o[2] &= 65535;
        o[2] += m[3] * n[2];
        o[1] += o[2] >>> 16;
        o[2] &= 65535;
        o[1] += m[1] * n[3];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[1] += m[2] * n[2];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[1] += m[3] * n[1];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[0] += m[0] * n[3] + m[1] * n[2] + m[2] * n[1] + m[3] * n[0];
        o[0] &= 65535;
        return [o[0] << 16 | o[1], o[2] << 16 | o[3]];
      }
      function _x64Rotl(m, n) {
        n %= 64;
        if (n === 32) {
          return [m[1], m[0]];
        } else if (n < 32) {
          return [m[0] << n | m[1] >>> 32 - n, m[1] << n | m[0] >>> 32 - n];
        } else {
          n -= 32;
          return [m[1] << n | m[0] >>> 32 - n, m[0] << n | m[1] >>> 32 - n];
        }
      }
      function _x64LeftShift(m, n) {
        n %= 64;
        if (n === 0) {
          return m;
        } else if (n < 32) {
          return [m[0] << n | m[1] >>> 32 - n, m[1] << n];
        } else {
          return [m[1] << n - 32, 0];
        }
      }
      function _x64Xor(m, n) {
        return [m[0] ^ n[0], m[1] ^ n[1]];
      }
      function _x64Fmix(h) {
        h = _x64Xor(h, [0, h[0] >>> 1]);
        h = _x64Multiply(h, [4283543511, 3981806797]);
        h = _x64Xor(h, [0, h[0] >>> 1]);
        h = _x64Multiply(h, [3301882366, 444984403]);
        h = _x64Xor(h, [0, h[0] >>> 1]);
        return h;
      }
      library.x86.hash32 = function(bytes, seed) {
        if (library.inputValidation && !_validBytes(bytes)) {
          return undefined2;
        }
        seed = seed || 0;
        var remainder = bytes.length % 4;
        var blocks = bytes.length - remainder;
        var h1 = seed;
        var k1 = 0;
        var c1 = 3432918353;
        var c2 = 461845907;
        for (var i = 0; i < blocks; i = i + 4) {
          k1 = bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24;
          k1 = _x86Multiply(k1, c1);
          k1 = _x86Rotl(k1, 15);
          k1 = _x86Multiply(k1, c2);
          h1 ^= k1;
          h1 = _x86Rotl(h1, 13);
          h1 = _x86Multiply(h1, 5) + 3864292196;
        }
        k1 = 0;
        switch (remainder) {
          case 3:
            k1 ^= bytes[i + 2] << 16;
          case 2:
            k1 ^= bytes[i + 1] << 8;
          case 1:
            k1 ^= bytes[i];
            k1 = _x86Multiply(k1, c1);
            k1 = _x86Rotl(k1, 15);
            k1 = _x86Multiply(k1, c2);
            h1 ^= k1;
        }
        h1 ^= bytes.length;
        h1 = _x86Fmix(h1);
        return h1 >>> 0;
      };
      library.x86.hash128 = function(bytes, seed) {
        if (library.inputValidation && !_validBytes(bytes)) {
          return undefined2;
        }
        seed = seed || 0;
        var remainder = bytes.length % 16;
        var blocks = bytes.length - remainder;
        var h1 = seed;
        var h2 = seed;
        var h3 = seed;
        var h4 = seed;
        var k1 = 0;
        var k2 = 0;
        var k3 = 0;
        var k4 = 0;
        var c1 = 597399067;
        var c2 = 2869860233;
        var c3 = 951274213;
        var c4 = 2716044179;
        for (var i = 0; i < blocks; i = i + 16) {
          k1 = bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24;
          k2 = bytes[i + 4] | bytes[i + 5] << 8 | bytes[i + 6] << 16 | bytes[i + 7] << 24;
          k3 = bytes[i + 8] | bytes[i + 9] << 8 | bytes[i + 10] << 16 | bytes[i + 11] << 24;
          k4 = bytes[i + 12] | bytes[i + 13] << 8 | bytes[i + 14] << 16 | bytes[i + 15] << 24;
          k1 = _x86Multiply(k1, c1);
          k1 = _x86Rotl(k1, 15);
          k1 = _x86Multiply(k1, c2);
          h1 ^= k1;
          h1 = _x86Rotl(h1, 19);
          h1 += h2;
          h1 = _x86Multiply(h1, 5) + 1444728091;
          k2 = _x86Multiply(k2, c2);
          k2 = _x86Rotl(k2, 16);
          k2 = _x86Multiply(k2, c3);
          h2 ^= k2;
          h2 = _x86Rotl(h2, 17);
          h2 += h3;
          h2 = _x86Multiply(h2, 5) + 197830471;
          k3 = _x86Multiply(k3, c3);
          k3 = _x86Rotl(k3, 17);
          k3 = _x86Multiply(k3, c4);
          h3 ^= k3;
          h3 = _x86Rotl(h3, 15);
          h3 += h4;
          h3 = _x86Multiply(h3, 5) + 2530024501;
          k4 = _x86Multiply(k4, c4);
          k4 = _x86Rotl(k4, 18);
          k4 = _x86Multiply(k4, c1);
          h4 ^= k4;
          h4 = _x86Rotl(h4, 13);
          h4 += h1;
          h4 = _x86Multiply(h4, 5) + 850148119;
        }
        k1 = 0;
        k2 = 0;
        k3 = 0;
        k4 = 0;
        switch (remainder) {
          case 15:
            k4 ^= bytes[i + 14] << 16;
          case 14:
            k4 ^= bytes[i + 13] << 8;
          case 13:
            k4 ^= bytes[i + 12];
            k4 = _x86Multiply(k4, c4);
            k4 = _x86Rotl(k4, 18);
            k4 = _x86Multiply(k4, c1);
            h4 ^= k4;
          case 12:
            k3 ^= bytes[i + 11] << 24;
          case 11:
            k3 ^= bytes[i + 10] << 16;
          case 10:
            k3 ^= bytes[i + 9] << 8;
          case 9:
            k3 ^= bytes[i + 8];
            k3 = _x86Multiply(k3, c3);
            k3 = _x86Rotl(k3, 17);
            k3 = _x86Multiply(k3, c4);
            h3 ^= k3;
          case 8:
            k2 ^= bytes[i + 7] << 24;
          case 7:
            k2 ^= bytes[i + 6] << 16;
          case 6:
            k2 ^= bytes[i + 5] << 8;
          case 5:
            k2 ^= bytes[i + 4];
            k2 = _x86Multiply(k2, c2);
            k2 = _x86Rotl(k2, 16);
            k2 = _x86Multiply(k2, c3);
            h2 ^= k2;
          case 4:
            k1 ^= bytes[i + 3] << 24;
          case 3:
            k1 ^= bytes[i + 2] << 16;
          case 2:
            k1 ^= bytes[i + 1] << 8;
          case 1:
            k1 ^= bytes[i];
            k1 = _x86Multiply(k1, c1);
            k1 = _x86Rotl(k1, 15);
            k1 = _x86Multiply(k1, c2);
            h1 ^= k1;
        }
        h1 ^= bytes.length;
        h2 ^= bytes.length;
        h3 ^= bytes.length;
        h4 ^= bytes.length;
        h1 += h2;
        h1 += h3;
        h1 += h4;
        h2 += h1;
        h3 += h1;
        h4 += h1;
        h1 = _x86Fmix(h1);
        h2 = _x86Fmix(h2);
        h3 = _x86Fmix(h3);
        h4 = _x86Fmix(h4);
        h1 += h2;
        h1 += h3;
        h1 += h4;
        h2 += h1;
        h3 += h1;
        h4 += h1;
        return ("00000000" + (h1 >>> 0).toString(16)).slice(-8) + ("00000000" + (h2 >>> 0).toString(16)).slice(-8) + ("00000000" + (h3 >>> 0).toString(16)).slice(-8) + ("00000000" + (h4 >>> 0).toString(16)).slice(-8);
      };
      library.x64.hash128 = function(bytes, seed) {
        if (library.inputValidation && !_validBytes(bytes)) {
          return undefined2;
        }
        seed = seed || 0;
        var remainder = bytes.length % 16;
        var blocks = bytes.length - remainder;
        var h1 = [0, seed];
        var h2 = [0, seed];
        var k1 = [0, 0];
        var k2 = [0, 0];
        var c1 = [2277735313, 289559509];
        var c2 = [1291169091, 658871167];
        for (var i = 0; i < blocks; i = i + 16) {
          k1 = [bytes[i + 4] | bytes[i + 5] << 8 | bytes[i + 6] << 16 | bytes[i + 7] << 24, bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24];
          k2 = [bytes[i + 12] | bytes[i + 13] << 8 | bytes[i + 14] << 16 | bytes[i + 15] << 24, bytes[i + 8] | bytes[i + 9] << 8 | bytes[i + 10] << 16 | bytes[i + 11] << 24];
          k1 = _x64Multiply(k1, c1);
          k1 = _x64Rotl(k1, 31);
          k1 = _x64Multiply(k1, c2);
          h1 = _x64Xor(h1, k1);
          h1 = _x64Rotl(h1, 27);
          h1 = _x64Add(h1, h2);
          h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 1390208809]);
          k2 = _x64Multiply(k2, c2);
          k2 = _x64Rotl(k2, 33);
          k2 = _x64Multiply(k2, c1);
          h2 = _x64Xor(h2, k2);
          h2 = _x64Rotl(h2, 31);
          h2 = _x64Add(h2, h1);
          h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 944331445]);
        }
        k1 = [0, 0];
        k2 = [0, 0];
        switch (remainder) {
          case 15:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 14]], 48));
          case 14:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 13]], 40));
          case 13:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 12]], 32));
          case 12:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 11]], 24));
          case 11:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 10]], 16));
          case 10:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 9]], 8));
          case 9:
            k2 = _x64Xor(k2, [0, bytes[i + 8]]);
            k2 = _x64Multiply(k2, c2);
            k2 = _x64Rotl(k2, 33);
            k2 = _x64Multiply(k2, c1);
            h2 = _x64Xor(h2, k2);
          case 8:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 7]], 56));
          case 7:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 6]], 48));
          case 6:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 5]], 40));
          case 5:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 4]], 32));
          case 4:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 3]], 24));
          case 3:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 2]], 16));
          case 2:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 1]], 8));
          case 1:
            k1 = _x64Xor(k1, [0, bytes[i]]);
            k1 = _x64Multiply(k1, c1);
            k1 = _x64Rotl(k1, 31);
            k1 = _x64Multiply(k1, c2);
            h1 = _x64Xor(h1, k1);
        }
        h1 = _x64Xor(h1, [0, bytes.length]);
        h2 = _x64Xor(h2, [0, bytes.length]);
        h1 = _x64Add(h1, h2);
        h2 = _x64Add(h2, h1);
        h1 = _x64Fmix(h1);
        h2 = _x64Fmix(h2);
        h1 = _x64Add(h1, h2);
        h2 = _x64Add(h2, h1);
        return ("00000000" + (h1[0] >>> 0).toString(16)).slice(-8) + ("00000000" + (h1[1] >>> 0).toString(16)).slice(-8) + ("00000000" + (h2[0] >>> 0).toString(16)).slice(-8) + ("00000000" + (h2[1] >>> 0).toString(16)).slice(-8);
      };
      if (typeof exports !== "undefined") {
        if (typeof module !== "undefined" && module.exports) {
          exports = module.exports = library;
        }
        exports.murmurHash3 = library;
      } else if (typeof define === "function" && define.amd) {
        define([], function() {
          return library;
        });
      } else {
        library._murmurHash3 = root.murmurHash3;
        library.noConflict = function() {
          root.murmurHash3 = library._murmurHash3;
          library._murmurHash3 = undefined2;
          library.noConflict = undefined2;
          return library;
        };
        root.murmurHash3 = library;
      }
    })(exports);
  }
});

// ../../node_modules/murmurhash3js-revisited/index.js
var require_murmurhash3js_revisited = __commonJS({
  "../../node_modules/murmurhash3js-revisited/index.js"(exports, module) {
    module.exports = require_murmurHash3js();
  }
});

// ../../node_modules/@libp2p/peer-collections/dist/src/util.js
function mapIterable(iter, map) {
  const iterator = {
    [Symbol.iterator]: () => {
      return iterator;
    },
    next: () => {
      const next = iter.next();
      const val = next.value;
      if (next.done === true || val == null) {
        const result = {
          done: true,
          value: void 0
        };
        return result;
      }
      return {
        done: false,
        value: map(val)
      };
    }
  };
  return iterator;
}

// ../../node_modules/@libp2p/peer-collections/dist/src/set.js
var PeerSet = class _PeerSet {
  set;
  constructor(set) {
    this.set = /* @__PURE__ */ new Set();
    if (set != null) {
      for (const key of set) {
        this.set.add(key.toString());
      }
    }
  }
  get size() {
    return this.set.size;
  }
  [Symbol.iterator]() {
    return this.values();
  }
  add(peer) {
    this.set.add(peer.toString());
  }
  clear() {
    this.set.clear();
  }
  delete(peer) {
    this.set.delete(peer.toString());
  }
  entries() {
    return mapIterable(this.set.entries(), (val) => {
      const peerId = peerIdFromString(val[0]);
      return [peerId, peerId];
    });
  }
  forEach(predicate) {
    this.set.forEach((str) => {
      const id = peerIdFromString(str);
      predicate(id, id, this);
    });
  }
  has(peer) {
    return this.set.has(peer.toString());
  }
  values() {
    return mapIterable(this.set.values(), (val) => {
      return peerIdFromString(val);
    });
  }
  intersection(other) {
    const output = new _PeerSet();
    for (const peerId of other) {
      if (this.has(peerId)) {
        output.add(peerId);
      }
    }
    return output;
  }
  difference(other) {
    const output = new _PeerSet();
    for (const peerId of this) {
      if (!other.has(peerId)) {
        output.add(peerId);
      }
    }
    return output;
  }
  union(other) {
    const output = new _PeerSet();
    for (const peerId of other) {
      output.add(peerId);
    }
    for (const peerId of this) {
      output.add(peerId);
    }
    return output;
  }
};

// ../../node_modules/@libp2p/peer-collections/dist/src/map.js
var PeerMap = class {
  map;
  constructor(map) {
    this.map = /* @__PURE__ */ new Map();
    if (map != null) {
      for (const [key, value] of map.entries()) {
        this.map.set(key.toString(), value);
      }
    }
  }
  [Symbol.iterator]() {
    return this.entries();
  }
  clear() {
    this.map.clear();
  }
  delete(peer) {
    return this.map.delete(peer.toString());
  }
  entries() {
    return mapIterable(this.map.entries(), (val) => {
      return [peerIdFromString(val[0]), val[1]];
    });
  }
  forEach(fn) {
    this.map.forEach((value, key) => {
      fn(value, peerIdFromString(key), this);
    });
  }
  get(peer) {
    return this.map.get(peer.toString());
  }
  has(peer) {
    return this.map.has(peer.toString());
  }
  set(peer, value) {
    this.map.set(peer.toString(), value);
  }
  keys() {
    return mapIterable(this.map.keys(), (val) => {
      return peerIdFromString(val);
    });
  }
  values() {
    return this.map.values();
  }
  get size() {
    return this.map.size;
  }
};

// ../../node_modules/@libp2p/utils/dist/src/filters/bloom-filter.js
var import_murmurhash3js_revisited = __toESM(require_murmurhash3js_revisited(), 1);
var LN2_SQUARED = Math.LN2 * Math.LN2;
var BloomFilter = class {
  seeds;
  bits;
  buffer;
  constructor(options = {}) {
    if (options.seeds != null) {
      this.seeds = options.seeds;
    } else {
      this.seeds = generateSeeds(options.hashes ?? 8);
    }
    this.bits = options.bits ?? 1024;
    this.buffer = alloc(Math.ceil(this.bits / 8));
  }
  /**
   * Add an item to the filter
   */
  add(item) {
    if (typeof item === "string") {
      item = fromString(item);
    }
    for (let i = 0; i < this.seeds.length; i++) {
      const hash = import_murmurhash3js_revisited.default.x86.hash32(item, this.seeds[i]);
      const bit = hash % this.bits;
      this.setbit(bit);
    }
  }
  /**
   * Test if the filter has an item. If it returns false it definitely does not
   * have the item. If it returns true, it probably has the item but there's
   * an `errorRate` chance it doesn't.
   */
  has(item) {
    if (typeof item === "string") {
      item = fromString(item);
    }
    for (let i = 0; i < this.seeds.length; i++) {
      const hash = import_murmurhash3js_revisited.default.x86.hash32(item, this.seeds[i]);
      const bit = hash % this.bits;
      const isSet = this.getbit(bit);
      if (!isSet) {
        return false;
      }
    }
    return true;
  }
  /**
   * Reset the filter
   */
  clear() {
    this.buffer.fill(0);
  }
  setbit(bit) {
    let pos = 0;
    let shift = bit;
    while (shift > 7) {
      pos++;
      shift -= 8;
    }
    let bitfield = this.buffer[pos];
    bitfield |= 1 << shift;
    this.buffer[pos] = bitfield;
  }
  getbit(bit) {
    let pos = 0;
    let shift = bit;
    while (shift > 7) {
      pos++;
      shift -= 8;
    }
    const bitfield = this.buffer[pos];
    return (bitfield & 1 << shift) !== 0;
  }
};
function createBloomFilter(itemcount, errorRate = 5e-3) {
  const opts = optimize(itemcount, errorRate);
  return new BloomFilter(opts);
}
function optimize(itemCount, errorRate = 5e-3) {
  const bits = Math.round(-1 * itemCount * Math.log(errorRate) / LN2_SQUARED);
  const hashes = Math.round(bits / itemCount * Math.LN2);
  return { bits, hashes };
}
function generateSeeds(count) {
  let buf;
  let j;
  const seeds = [];
  for (let i = 0; i < count; i++) {
    buf = new Uint8ArrayList(randomBytes(4));
    seeds[i] = buf.getUint32(0, true);
    for (j = 0; j < i; j++) {
      if (seeds[i] === seeds[j]) {
        i--;
        break;
      }
    }
  }
  return seeds;
}

// ../../node_modules/@libp2p/utils/dist/src/filters/fingerprint.js
var MAX_FINGERPRINT_SIZE = 64;
var Fingerprint = class {
  fp;
  h;
  seed;
  constructor(buf, hash, seed, fingerprintSize = 2) {
    if (fingerprintSize > MAX_FINGERPRINT_SIZE) {
      throw new TypeError("Invalid Fingerprint Size");
    }
    const fnv = hash.hashV(buf, seed);
    const fp = alloc(fingerprintSize);
    for (let i = 0; i < fp.length; i++) {
      fp[i] = fnv[i];
    }
    if (fp.length === 0) {
      fp[0] = 7;
    }
    this.fp = fp;
    this.h = hash;
    this.seed = seed;
  }
  hash() {
    return this.h.hash(this.fp, this.seed);
  }
  equals(other) {
    if (!(other?.fp instanceof Uint8Array)) {
      return false;
    }
    return equals(this.fp, other.fp);
  }
};

// ../../node_modules/@libp2p/utils/dist/src/filters/utils.js
function getRandomInt(min, max) {
  return Math.floor(Math.random() * (max - min)) + min;
}

// ../../node_modules/@libp2p/utils/dist/src/filters/bucket.js
var Bucket = class {
  contents;
  constructor(size) {
    this.contents = new Array(size).fill(null);
  }
  has(fingerprint) {
    if (!(fingerprint instanceof Fingerprint)) {
      throw new TypeError("Invalid Fingerprint");
    }
    return this.contents.some((fp) => {
      return fingerprint.equals(fp);
    });
  }
  add(fingerprint) {
    if (!(fingerprint instanceof Fingerprint)) {
      throw new TypeError("Invalid Fingerprint");
    }
    for (let i = 0; i < this.contents.length; i++) {
      if (this.contents[i] == null) {
        this.contents[i] = fingerprint;
        return true;
      }
    }
    return true;
  }
  swap(fingerprint) {
    if (!(fingerprint instanceof Fingerprint)) {
      throw new TypeError("Invalid Fingerprint");
    }
    const i = getRandomInt(0, this.contents.length - 1);
    const current = this.contents[i];
    this.contents[i] = fingerprint;
    return current;
  }
  remove(fingerprint) {
    if (!(fingerprint instanceof Fingerprint)) {
      throw new TypeError("Invalid Fingerprint");
    }
    const found = this.contents.findIndex((fp) => {
      return fingerprint.equals(fp);
    });
    if (found > -1) {
      this.contents[found] = null;
      return true;
    } else {
      return false;
    }
  }
};

// ../../node_modules/@sindresorhus/fnv1a/index.js
var FNV_PRIMES = {
  32: 16777619n,
  64: 1099511628211n,
  128: 309485009821345068724781371n,
  256: 374144419156711147060143317175368453031918731002211n,
  512: 35835915874844867368919076489095108449946327955754392558399825615420669938882575126094039892345713852759n,
  1024: 5016456510113118655434598811035278955030765345404790744303017523831112055108147451509157692220295382716162651878526895249385292291816524375083746691371804094271873160484737966720260389217684476157468082573n
};
var FNV_OFFSETS = {
  32: 2166136261n,
  64: 14695981039346656037n,
  128: 144066263297769815596495629667062367629n,
  256: 100029257958052580907070968620625704837092796014241193945225284501741471925557n,
  512: 9659303129496669498009435400716310466090418745672637896108374329434462657994582932197716438449813051892206539805784495328239340083876191928701583869517785n,
  1024: 14197795064947621068722070641403218320880622795441933960878474914617582723252296732303717722150864096521202355549365628174669108571814760471015076148029755969804077320157692458563003215304957150157403644460363550505412711285966361610267868082893823963790439336411086884584107735010676915n
};
var cachedEncoder = new globalThis.TextEncoder();
function fnv1aUint8Array(uint8Array, size) {
  const fnvPrime = FNV_PRIMES[size];
  let hash = FNV_OFFSETS[size];
  for (let index = 0; index < uint8Array.length; index++) {
    hash ^= BigInt(uint8Array[index]);
    hash = BigInt.asUintN(size, hash * fnvPrime);
  }
  return hash;
}
function fnv1aEncodeInto(string, size, utf8Buffer) {
  if (utf8Buffer.length === 0) {
    throw new Error("The `utf8Buffer` option must have a length greater than zero");
  }
  const fnvPrime = FNV_PRIMES[size];
  let hash = FNV_OFFSETS[size];
  let remaining = string;
  while (remaining.length > 0) {
    const result = cachedEncoder.encodeInto(remaining, utf8Buffer);
    remaining = remaining.slice(result.read);
    for (let index = 0; index < result.written; index++) {
      hash ^= BigInt(utf8Buffer[index]);
      hash = BigInt.asUintN(size, hash * fnvPrime);
    }
  }
  return hash;
}
function fnv1a(value, { size = 32, utf8Buffer } = {}) {
  if (!FNV_PRIMES[size]) {
    throw new Error("The `size` option must be one of 32, 64, 128, 256, 512, or 1024");
  }
  if (typeof value === "string") {
    if (utf8Buffer) {
      return fnv1aEncodeInto(value, size, utf8Buffer);
    }
    value = cachedEncoder.encode(value);
  }
  return fnv1aUint8Array(value, size);
}

// ../../node_modules/@libp2p/utils/dist/src/filters/hashes.js
var import_murmurhash3js_revisited2 = __toESM(require_murmurhash3js_revisited(), 1);
var fnv1a2 = {
  hash: (input) => {
    return Number(fnv1a(input, {
      size: 32
    }));
  },
  hashV: (input, seed) => {
    return numberToBuffer(fnv1a2.hash(input, seed));
  }
};
function numberToBuffer(num) {
  let hex = num.toString(16);
  if (hex.length % 2 === 1) {
    hex = `0${hex}`;
  }
  return fromString(hex, "base16");
}

// ../../node_modules/@libp2p/utils/dist/src/filters/cuckoo-filter.js
var maxCuckooCount = 500;
var CuckooFilter = class {
  bucketSize;
  filterSize;
  fingerprintSize;
  buckets;
  count;
  hash;
  seed;
  constructor(init) {
    this.filterSize = init.filterSize;
    this.bucketSize = init.bucketSize ?? 4;
    this.fingerprintSize = init.fingerprintSize ?? 2;
    this.count = 0;
    this.buckets = [];
    this.hash = init.hash ?? fnv1a2;
    this.seed = init.seed ?? getRandomInt(0, Math.pow(2, 10));
  }
  add(item) {
    if (typeof item === "string") {
      item = fromString(item);
    }
    const fingerprint = new Fingerprint(item, this.hash, this.seed, this.fingerprintSize);
    const j = this.hash.hash(item, this.seed) % this.filterSize;
    const k = (j ^ fingerprint.hash()) % this.filterSize;
    if (this.buckets[j] == null) {
      this.buckets[j] = new Bucket(this.bucketSize);
    }
    if (this.buckets[k] == null) {
      this.buckets[k] = new Bucket(this.bucketSize);
    }
    if (this.buckets[j].add(fingerprint) || this.buckets[k].add(fingerprint)) {
      this.count++;
      return true;
    }
    const rand = [j, k];
    let i = rand[getRandomInt(0, rand.length - 1)];
    if (this.buckets[i] == null) {
      this.buckets[i] = new Bucket(this.bucketSize);
    }
    for (let n = 0; n < maxCuckooCount; n++) {
      const swapped = this.buckets[i].swap(fingerprint);
      if (swapped == null) {
        continue;
      }
      i = (i ^ swapped.hash()) % this.filterSize;
      if (this.buckets[i] == null) {
        this.buckets[i] = new Bucket(this.bucketSize);
      }
      if (this.buckets[i].add(swapped)) {
        this.count++;
        return true;
      } else {
        continue;
      }
    }
    return false;
  }
  has(item) {
    if (typeof item === "string") {
      item = fromString(item);
    }
    const fingerprint = new Fingerprint(item, this.hash, this.seed, this.fingerprintSize);
    const j = this.hash.hash(item, this.seed) % this.filterSize;
    const inJ = this.buckets[j]?.has(fingerprint) ?? false;
    if (inJ) {
      return inJ;
    }
    const k = (j ^ fingerprint.hash()) % this.filterSize;
    return this.buckets[k]?.has(fingerprint) ?? false;
  }
  remove(item) {
    if (typeof item === "string") {
      item = fromString(item);
    }
    const fingerprint = new Fingerprint(item, this.hash, this.seed, this.fingerprintSize);
    const j = this.hash.hash(item, this.seed) % this.filterSize;
    const inJ = this.buckets[j]?.remove(fingerprint) ?? false;
    if (inJ) {
      this.count--;
      return inJ;
    }
    const k = (j ^ fingerprint.hash()) % this.filterSize;
    const inK = this.buckets[k]?.remove(fingerprint) ?? false;
    if (inK) {
      this.count--;
    }
    return inK;
  }
  get reliable() {
    return Math.floor(100 * (this.count / this.filterSize)) <= 90;
  }
};
var MAX_LOAD = {
  1: 0.5,
  2: 0.84,
  4: 0.95,
  8: 0.98
};
function calculateBucketSize(errorRate = 1e-3) {
  if (errorRate > 2e-3) {
    return 2;
  }
  if (errorRate > 1e-5) {
    return 4;
  }
  return 8;
}
function optimize2(maxItems, errorRate = 1e-3) {
  const bucketSize = calculateBucketSize(errorRate);
  const load = MAX_LOAD[bucketSize];
  const filterSize = Math.round(maxItems / load);
  const fingerprintSize = Math.min(Math.ceil(Math.log2(1 / errorRate) + Math.log2(2 * bucketSize)), MAX_FINGERPRINT_SIZE);
  return {
    filterSize,
    bucketSize,
    fingerprintSize
  };
}

// ../../node_modules/@libp2p/utils/dist/src/filters/scalable-cuckoo-filter.js
var ScalableCuckooFilter = class {
  filterSize;
  bucketSize;
  fingerprintSize;
  scale;
  filterSeries;
  hash;
  seed;
  constructor(init) {
    this.bucketSize = init.bucketSize ?? 4;
    this.filterSize = init.filterSize ?? (1 << 18) / this.bucketSize;
    this.fingerprintSize = init.fingerprintSize ?? 2;
    this.scale = init.scale ?? 2;
    this.hash = init.hash ?? fnv1a2;
    this.seed = init.seed ?? getRandomInt(0, Math.pow(2, 10));
    this.filterSeries = [
      new CuckooFilter({
        filterSize: this.filterSize,
        bucketSize: this.bucketSize,
        fingerprintSize: this.fingerprintSize,
        hash: this.hash,
        seed: this.seed
      })
    ];
  }
  add(item) {
    if (typeof item === "string") {
      item = fromString(item);
    }
    if (this.has(item)) {
      return true;
    }
    let current = this.filterSeries.find((cuckoo) => {
      return cuckoo.reliable;
    });
    if (current == null) {
      const curSize = this.filterSize * Math.pow(this.scale, this.filterSeries.length);
      current = new CuckooFilter({
        filterSize: curSize,
        bucketSize: this.bucketSize,
        fingerprintSize: this.fingerprintSize,
        hash: this.hash,
        seed: this.seed
      });
      this.filterSeries.push(current);
    }
    return current.add(item);
  }
  has(item) {
    if (typeof item === "string") {
      item = fromString(item);
    }
    for (let i = 0; i < this.filterSeries.length; i++) {
      if (this.filterSeries[i].has(item)) {
        return true;
      }
    }
    return false;
  }
  remove(item) {
    if (typeof item === "string") {
      item = fromString(item);
    }
    for (let i = 0; i < this.filterSeries.length; i++) {
      if (this.filterSeries[i].remove(item)) {
        return true;
      }
    }
    return false;
  }
  get count() {
    return this.filterSeries.reduce((acc, curr) => {
      return acc + curr.count;
    }, 0);
  }
};
function createScalableCuckooFilter(maxItems, errorRate = 1e-3, options) {
  return new ScalableCuckooFilter({
    ...optimize2(maxItems, errorRate),
    ...options ?? {}
  });
}

// ../../node_modules/@libp2p/peer-collections/dist/src/filter.js
var PeerFilter = class {
  filter;
  constructor(size, errorRate) {
    this.filter = createScalableCuckooFilter(size, errorRate);
  }
  has(peerId) {
    return this.filter.has(peerId.toBytes());
  }
  add(peerId) {
    this.filter.add(peerId.toBytes());
  }
  remove(peerId) {
    this.filter.remove?.(peerId.toBytes());
  }
};
function peerFilter(size, errorRate = 1e-3) {
  return new PeerFilter(size, errorRate);
}

// ../../node_modules/any-signal/dist/src/index.js
function anySignal(signals) {
  const controller = new globalThis.AbortController();
  function onAbort() {
    controller.abort();
    for (const signal2 of signals) {
      if (signal2?.removeEventListener != null) {
        signal2.removeEventListener("abort", onAbort);
      }
    }
  }
  for (const signal2 of signals) {
    if (signal2?.aborted === true) {
      onAbort();
      break;
    }
    if (signal2?.addEventListener != null) {
      signal2.addEventListener("abort", onAbort);
    }
  }
  function clear() {
    for (const signal2 of signals) {
      if (signal2?.removeEventListener != null) {
        signal2.removeEventListener("abort", onAbort);
      }
    }
  }
  const signal = controller.signal;
  signal.clear = clear;
  return signal;
}

// ../../node_modules/race-event/dist/src/index.js
var AbortError2 = class extends Error {
  type;
  code;
  constructor(message, code) {
    super(message ?? "The operation was aborted");
    this.type = "aborted";
    this.name = "AbortError";
    this.code = code ?? "ABORT_ERR";
  }
};
async function raceEvent(emitter, eventName, signal, opts) {
  const error = new AbortError2(opts?.errorMessage, opts?.errorCode);
  if (signal?.aborted === true) {
    return Promise.reject(error);
  }
  return new Promise((resolve, reject) => {
    function removeListeners() {
      signal?.removeEventListener("abort", abortListener);
      emitter.removeEventListener(eventName, eventListener);
      if (opts?.errorEvent != null) {
        emitter.removeEventListener(opts.errorEvent, errorEventListener);
      }
    }
    const eventListener = (evt) => {
      try {
        if (opts?.filter?.(evt) === false) {
          return;
        }
      } catch (err) {
        removeListeners();
        reject(err);
        return;
      }
      removeListeners();
      resolve(evt);
    };
    const errorEventListener = (evt) => {
      removeListeners();
      reject(evt.detail);
    };
    const abortListener = () => {
      removeListeners();
      reject(error);
    };
    signal?.addEventListener("abort", abortListener);
    emitter.addEventListener(eventName, eventListener);
    if (opts?.errorEvent != null) {
      emitter.addEventListener(opts.errorEvent, errorEventListener);
    }
  });
}

// ../../node_modules/@libp2p/utils/dist/src/queue/recipient.js
var JobRecipient = class {
  deferred;
  signal;
  constructor(signal) {
    this.signal = signal;
    this.deferred = pDefer();
    this.onAbort = this.onAbort.bind(this);
    this.signal?.addEventListener("abort", this.onAbort);
  }
  onAbort() {
    this.deferred.reject(this.signal?.reason ?? new AbortError());
  }
  cleanup() {
    this.signal?.removeEventListener("abort", this.onAbort);
  }
};

// ../../node_modules/@libp2p/utils/dist/src/queue/job.js
function randomId() {
  return `${parseInt(String(Math.random() * 1e9), 10).toString()}${Date.now()}`;
}
var Job = class {
  id;
  fn;
  options;
  recipients;
  status;
  timeline;
  controller;
  constructor(fn, options) {
    this.id = randomId();
    this.status = "queued";
    this.fn = fn;
    this.options = options;
    this.recipients = [];
    this.timeline = {
      created: Date.now()
    };
    this.controller = new AbortController();
    setMaxListeners(Infinity, this.controller.signal);
    this.onAbort = this.onAbort.bind(this);
  }
  abort(err) {
    this.controller.abort(err);
  }
  onAbort() {
    const allAborted = this.recipients.reduce((acc, curr) => {
      return acc && curr.signal?.aborted === true;
    }, true);
    if (allAborted) {
      this.controller.abort(new AbortError());
      this.cleanup();
    }
  }
  async join(options = {}) {
    const recipient = new JobRecipient(options.signal);
    this.recipients.push(recipient);
    options.signal?.addEventListener("abort", this.onAbort);
    return recipient.deferred.promise;
  }
  async run() {
    this.status = "running";
    this.timeline.started = Date.now();
    try {
      this.controller.signal.throwIfAborted();
      const result = await raceSignal(this.fn({
        ...this.options ?? {},
        signal: this.controller.signal
      }), this.controller.signal);
      this.recipients.forEach((recipient) => {
        recipient.deferred.resolve(result);
      });
      this.status = "complete";
    } catch (err) {
      this.recipients.forEach((recipient) => {
        recipient.deferred.reject(err);
      });
      this.status = "errored";
    } finally {
      this.timeline.finished = Date.now();
      this.cleanup();
    }
  }
  cleanup() {
    this.recipients.forEach((recipient) => {
      recipient.cleanup();
      recipient.signal?.removeEventListener("abort", this.onAbort);
    });
  }
};

// ../../node_modules/@libp2p/utils/dist/src/queue/index.js
var Queue = class extends TypedEventEmitter {
  concurrency;
  queue;
  pending;
  sort;
  constructor(init = {}) {
    super();
    this.concurrency = init.concurrency ?? Number.POSITIVE_INFINITY;
    this.pending = 0;
    if (init.metricName != null) {
      init.metrics?.registerMetricGroup(init.metricName, {
        calculate: () => {
          return {
            size: this.queue.length,
            running: this.pending,
            queued: this.queue.length - this.pending
          };
        }
      });
    }
    this.sort = init.sort;
    this.queue = [];
  }
  tryToStartAnother() {
    if (this.size === 0) {
      queueMicrotask(() => {
        this.safeDispatchEvent("empty");
      });
      if (this.running === 0) {
        queueMicrotask(() => {
          this.safeDispatchEvent("idle");
        });
      }
      return false;
    }
    if (this.pending < this.concurrency) {
      let job;
      for (const j of this.queue) {
        if (j.status === "queued") {
          job = j;
          break;
        }
      }
      if (job == null) {
        return false;
      }
      this.safeDispatchEvent("active");
      this.pending++;
      void job.run().finally(() => {
        for (let i = 0; i < this.queue.length; i++) {
          if (this.queue[i] === job) {
            this.queue.splice(i, 1);
            break;
          }
        }
        this.pending--;
        this.tryToStartAnother();
        this.safeDispatchEvent("next");
      });
      return true;
    }
    return false;
  }
  enqueue(job) {
    this.queue.push(job);
    if (this.sort != null) {
      this.queue.sort(this.sort);
    }
  }
  /**
   * Adds a sync or async task to the queue. Always returns a promise.
   */
  async add(fn, options) {
    options?.signal?.throwIfAborted();
    const job = new Job(fn, options);
    this.enqueue(job);
    this.safeDispatchEvent("add");
    this.tryToStartAnother();
    return job.join(options).then((result) => {
      this.safeDispatchEvent("completed", { detail: result });
      this.safeDispatchEvent("success", { detail: { job, result } });
      return result;
    }).catch((err) => {
      if (job.status === "queued") {
        for (let i = 0; i < this.queue.length; i++) {
          if (this.queue[i] === job) {
            this.queue.splice(i, 1);
            break;
          }
        }
      }
      this.safeDispatchEvent("error", { detail: err });
      this.safeDispatchEvent("failure", { detail: { job, error: err } });
      throw err;
    });
  }
  /**
   * Clear the queue
   */
  clear() {
    this.queue.splice(0, this.queue.length);
  }
  /**
   * Abort all jobs in the queue and clear it
   */
  abort() {
    this.queue.forEach((job) => {
      job.abort(new AbortError());
    });
    this.clear();
  }
  /**
   * Can be called multiple times. Useful if you for example add additional items at a later time.
   *
   * @returns A promise that settles when the queue becomes empty.
   */
  async onEmpty(options) {
    if (this.size === 0) {
      return;
    }
    await raceEvent(this, "empty", options?.signal);
  }
  /**
   * @returns A promise that settles when the queue size is less than the given
   * limit: `queue.size < limit`.
   *
   * If you want to avoid having the queue grow beyond a certain size you can
   * `await queue.onSizeLessThan()` before adding a new item.
   *
   * Note that this only limits the number of items waiting to start. There
   * could still be up to `concurrency` jobs already running that this call does
   * not include in its calculation.
   */
  async onSizeLessThan(limit, options) {
    if (this.size < limit) {
      return;
    }
    await raceEvent(this, "next", options?.signal, {
      filter: () => this.size < limit
    });
  }
  /**
   * The difference with `.onEmpty` is that `.onIdle` guarantees that all work
   * from the queue has finished. `.onEmpty` merely signals that the queue is
   * empty, but it could mean that some promises haven't completed yet.
   *
   * @returns A promise that settles when the queue becomes empty, and all
   * promises have completed; `queue.size === 0 && queue.pending === 0`.
   */
  async onIdle(options) {
    if (this.pending === 0 && this.size === 0) {
      return;
    }
    await raceEvent(this, "idle", options?.signal);
  }
  /**
   * Size of the queue including running items
   */
  get size() {
    return this.queue.length;
  }
  /**
   * The number of queued items waiting to run.
   */
  get queued() {
    return this.queue.length - this.pending;
  }
  /**
   * The number of items currently running.
   */
  get running() {
    return this.pending;
  }
  /**
   * Returns an async generator that makes it easy to iterate over the results
   * of jobs added to the queue.
   *
   * The generator will end when the queue becomes idle, that is there are no
   * jobs running and no jobs that have yet to run.
   *
   * If you need to keep the queue open indefinitely, consider using it-pushable
   * instead.
   */
  async *toGenerator(options) {
    options?.signal?.throwIfAborted();
    const stream = pushable({
      objectMode: true
    });
    const cleanup = (err) => {
      if (err != null) {
        this.abort();
      } else {
        this.clear();
      }
      stream.end(err);
    };
    const onQueueJobComplete = (evt) => {
      if (evt.detail != null) {
        stream.push(evt.detail);
      }
    };
    const onQueueError = (evt) => {
      cleanup(evt.detail);
    };
    const onQueueIdle = () => {
      cleanup();
    };
    const onSignalAbort = () => {
      cleanup(new CodeError("Queue aborted", "ERR_QUEUE_ABORTED"));
    };
    this.addEventListener("completed", onQueueJobComplete);
    this.addEventListener("error", onQueueError);
    this.addEventListener("idle", onQueueIdle);
    options?.signal?.addEventListener("abort", onSignalAbort);
    try {
      yield* stream;
    } finally {
      this.removeEventListener("completed", onQueueJobComplete);
      this.removeEventListener("error", onQueueError);
      this.removeEventListener("idle", onQueueIdle);
      options?.signal?.removeEventListener("abort", onSignalAbort);
      cleanup();
    }
  }
};

// ../../node_modules/@libp2p/utils/dist/src/peer-queue.js
var PeerQueue = class extends Queue {
  has(peerId) {
    return this.find(peerId) != null;
  }
  find(peerId) {
    return this.queue.find((job) => {
      return peerId.equals(job.options.peerId);
    });
  }
};

export {
  anySignal,
  PeerMap,
  PeerSet,
  createBloomFilter,
  createScalableCuckooFilter,
  peerFilter,
  raceEvent,
  Queue,
  PeerQueue
};
//# sourceMappingURL=chunk-P772C3S3.js.map
